{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, future_num_frames, seq_len, num_layers=1):\n",
    "        super(Frame_LSTM, self).__init__()\n",
    "        self.future_num_frames = future_num_frames\n",
    "        \n",
    "        self.lstm = nn.LSTM(2, hidden_size1, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size2, 2*future_num_frames)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        out, (h_n, c_n) = self.lstm(data)\n",
    "        \n",
    "        h_n = h_n.squeeze(0)\n",
    "        \n",
    "        out = self.fc1(h_n)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out.view(out.shape[0], self.future_num_frames, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"A:/CSCI 566 Project/\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "# cfg = load_config_data(\"./configs/Frame_LSTM_Config.yaml\")\n",
    "cfg = {'format_version': 4,\n",
    " 'model_params': {'history_num_frames': 10,\n",
    "  'history_step_size': 1,\n",
    "  'history_delta_time': 0.1,\n",
    "  'future_num_frames': 50,\n",
    "  'future_step_size': 1,\n",
    "  'future_delta_time': 0.1},\n",
    " 'raster_params': {'raster_size': [224, 224],\n",
    "  'pixel_size': [0.5, 0.5],\n",
    "  'ego_center': [0.5, 0.5],\n",
    "  'map_type': 'py_semantic',\n",
    "  'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "  'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "  'dataset_meta_key': 'meta.json',\n",
    "  'filter_agents_threshold': 0.5,\n",
    "  'disable_traffic_light_faces': False},\n",
    " 'train_data_loader': {'key': 'scenes/train.zarr',\n",
    "  'batch_size': 16,\n",
    "  'shuffle': True,\n",
    "  'num_workers': 1},\n",
    " 'val_data_loader': {'key': 'scenes/validate.zarr',\n",
    "  'batch_size': 16,\n",
    "  'shuffle': False,\n",
    "  'num_workers': 1},\n",
    " 'test_data_loader': {'key': 'scenes/test.zarr',\n",
    "  'batch_size': 32,\n",
    "  'shuffle': False,\n",
    "  'num_workers': 1},\n",
    " 'train_params': {'checkpoint_every_n_steps': 100,\n",
    "  'max_num_steps': 10000,\n",
    "  'eval_every_n_steps': 100}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INIT DATASET\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "FUTURE_NUM_FRAMES = cfg['model_params']['future_num_frames']\n",
    "SEQ_LEN = cfg['model_params']['history_num_frames'] + 1\n",
    "\n",
    "\n",
    "\n",
    "# ===== INIT  VAL DATASET\n",
    "val_cfg = cfg[\"val_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "val_zarr = ChunkedDataset(dm.require(val_cfg[\"key\"])).open()\n",
    "val_dataset = AgentDataset(cfg, val_zarr, rasterizer)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                              shuffle=val_cfg[\"shuffle\"],\n",
    "                              batch_size=val_cfg[\"batch_size\"])\n",
    "                              #num_workers=train_cfg[\"num_workers\"])\n",
    "    \n",
    "# print(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Frame_LSTM(256, 128, FUTURE_NUM_FRAMES, SEQ_LEN).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6389812231063843 loss(avg): 4.874071678519249 loss_val(avg): 3.4550647827790817:  27%|â–Ž| 2733/10000 [2:45:51<35"
     ]
    }
   ],
   "source": [
    "# ==== TRAIN LOOP\n",
    "tr_it = iter(train_dataloader)\n",
    "vl_it = iter(val_dataloader)\n",
    "progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]), position=0)\n",
    "checkpoint_n = cfg[\"train_params\"][\"checkpoint_every_n_steps\"]\n",
    "losses_train = []\n",
    "curr_losses = []\n",
    "losses_avg = []\n",
    "\n",
    "losses_val = []\n",
    "val_avg = []\n",
    "\n",
    "hidden = None\n",
    "\n",
    "num_frames = 20\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    pred = model.forward(torch.flip(data['history_positions'], [1]).to(device))\n",
    "    \n",
    "    targets = data['target_positions'].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "\n",
    "    # Backward pass\n",
    "    loss = criterion(pred, targets)\n",
    "    loss = loss * target_availabilities\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses_train.append(loss.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            val_data = next(vl_it)\n",
    "        except StopIteration:\n",
    "            vl_it = iter(val_dataloader)\n",
    "            val_data = next(vl_it)\n",
    "\n",
    "        model.eval()\n",
    "        # Forward pass\n",
    "        pred = model.forward(torch.flip(val_data['history_positions'], [1]).to(device))\n",
    "    \n",
    "        targets = val_data['target_positions'].to(device)\n",
    "        target_availabilities = val_data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "\n",
    "        # Backward pass\n",
    "        v_loss = criterion(pred, targets)\n",
    "        v_loss = v_loss * target_availabilities\n",
    "        v_loss = v_loss.mean()\n",
    "        losses_val.append(v_loss.item())\n",
    "    \n",
    "    if (i % checkpoint_n) == checkpoint_n - 1:\n",
    "        with open('Frame_LSTM_val.csv','a') as fd:\n",
    "            for loss in losses_val:\n",
    "                fd.write(f\"{i},{loss}\\n\")\n",
    "                \n",
    "        with open('Frame_LSTM_train.csv','a') as fd:\n",
    "            for loss in losses_train:\n",
    "                fd.write(f\"{i},{loss}\\n\")\n",
    "\n",
    "        train_avg_loss = np.mean(losses_train)\n",
    "        val_avg_loss =  np.mean(losses_val)\n",
    "        \n",
    "        losses_train = []\n",
    "        losses_val = []\n",
    "        \n",
    "        \n",
    "        with open('Frame_LSTM_train_avg.csv','a') as fd:\n",
    "            fd.write(f\"{i},{train_avg_loss}\\n\")\n",
    "            \n",
    "        with open('Frame_LSTM_val_avg.csv','a') as fd:\n",
    "            fd.write(f\"{i},{val_avg_loss}\\n\")\n",
    "            \n",
    "        progress_bar.set_description(f\"loss: {loss} loss(avg): {train_avg_loss} loss_val(avg): {val_avg_loss}\")\n",
    "        if (i+1) % 250 == 0:\n",
    "            torch.save(model.state_dict(), f'saved_models/Frame_LSTM{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame_Partial_LSTM9999\n",
    "train_cfg = cfg[\"test_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "FUTURE_NUM_FRAMES = cfg['model_params']['future_num_frames']\n",
    "SEQ_LEN = cfg['model_params']['history_num_frames'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371979\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Frame_LSTM(256, 128, FUTURE_NUM_FRAMES, SEQ_LEN).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "model.load_state_dict(torch.load('saved_models/Frame_LSTM9999.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [22:26<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "tr_it = iter(train_dataloader)\n",
    "progress_bar = tqdm(range(1000), position=0)\n",
    "checkpoint_n = cfg[\"train_params\"][\"checkpoint_every_n_steps\"]\n",
    "losses_train = []\n",
    "curr_losses = []\n",
    "losses_avg = []\n",
    "\n",
    "losses_val = []\n",
    "val_avg = []\n",
    "\n",
    "hidden = None\n",
    "\n",
    "num_frames = 20\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    \n",
    "    # Train\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(torch.flip(data['history_positions'], [1]).to(device))\n",
    "\n",
    "        targets = data['target_positions'].to(device)\n",
    "        target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "\n",
    "        # Backward pass\n",
    "        loss = criterion(pred, targets)\n",
    "        loss = loss * target_availabilities\n",
    "        loss = loss.mean()\n",
    "    \n",
    "        losses_train.append(loss.item())\n",
    "    \n",
    "with open('Frame_LSTM_test.csv','a') as fd:\n",
    "    for loss in losses_train:\n",
    "        fd.write(f\"{i},{loss}\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss: 2.2572304171698523\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Test Loss: {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
