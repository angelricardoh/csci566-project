{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "        def __init__(self, hidden_size, num_layers):\n",
    "            super(Encoder, self).__init__()        \n",
    "            self.lstm = nn.LSTM(2, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        def forward(self, data):\n",
    "            out, hidden = self.lstm(data)\n",
    "\n",
    "            return out, hidden\n",
    "        \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, future_num_frames, seq_len, decoder_seq_len, num_layers=1, input_size=256):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.future_num_frames = future_num_frames\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        \n",
    "        self.encoder_lstm = Encoder(hidden_size1, num_layers)\n",
    "        \n",
    "        self.decoder = nn.LSTM(input_size, hidden_size1, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size2, 2)\n",
    "        \n",
    "    def forward(self, data, device):\n",
    "        _, hidden = self.encoder_lstm(data)\n",
    "        \n",
    "        batch_size = data.shape[0]\n",
    "        out, _ = self.decoder(torch.ones(batch_size, self.decoder_seq_len, self.input_size).to(device), hidden)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out.view(batch_size, self.future_num_frames, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"A:/CSCI 566 Project/\"\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "# cfg = load_config_data(\"./configs/Frame_LSTM_Config.yaml\")\n",
    "cfg = {'format_version': 4,\n",
    " 'model_params': {'history_num_frames': 10,\n",
    "  'history_step_size': 1,\n",
    "  'history_delta_time': 0.1,\n",
    "  'future_num_frames': 50,\n",
    "  'future_step_size': 1,\n",
    "  'future_delta_time': 0.1},\n",
    " 'raster_params': {'raster_size': [224, 224],\n",
    "  'pixel_size': [0.5, 0.5],\n",
    "  'ego_center': [0.5, 0.5],\n",
    "  'map_type': 'py_semantic',\n",
    "  'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "  'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "  'dataset_meta_key': 'meta.json',\n",
    "  'filter_agents_threshold': 0.5,\n",
    "  'disable_traffic_light_faces': False},\n",
    " 'train_data_loader': {'key': 'scenes/train.zarr',\n",
    "  'batch_size': 64,\n",
    "  'shuffle': True,\n",
    "  'num_workers': 1},\n",
    " 'val_data_loader': {'key': 'scenes/validate.zarr',\n",
    "  'batch_size': 64,\n",
    "  'shuffle': False,\n",
    "  'num_workers': 1},\n",
    " 'test_data_loader': {'key': 'scenes/test.zarr',\n",
    "  'batch_size': 32,\n",
    "  'shuffle': False,\n",
    "  'num_workers': 1},\n",
    " 'train_params': {'checkpoint_every_n_steps': 250,\n",
    "  'max_num_steps': 100000,\n",
    "  'eval_every_n_steps': 100}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== INIT DATASET\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "FUTURE_NUM_FRAMES = cfg['model_params']['future_num_frames']\n",
    "SEQ_LEN = cfg['model_params']['history_num_frames'] + 1\n",
    "\n",
    "\n",
    "\n",
    "# ===== INIT  VAL DATASET\n",
    "val_cfg = cfg[\"val_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "val_zarr = ChunkedDataset(dm.require(val_cfg[\"key\"])).open()\n",
    "val_dataset = AgentDataset(cfg, val_zarr, rasterizer)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                              shuffle=val_cfg[\"shuffle\"],\n",
    "                              batch_size=val_cfg[\"batch_size\"])\n",
    "                              #num_workers=train_cfg[\"num_workers\"])\n",
    "    \n",
    "# print(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 64\n",
    "model = Seq2Seq(hidden_size, 16, FUTURE_NUM_FRAMES, SEQ_LEN, FUTURE_NUM_FRAMES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 83.40279388427734 loss(avg): 88.69890975952148 loss_val(avg): 30.391950607299805:   0%| | 4/100000 [00:18<131:03:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-28d63a3e2127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvl_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mvl_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\dataset\\agent.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mstate_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_index\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscene_index\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscene_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_scene_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscene_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"AgentDataset\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\dataset\\ego.py\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, scene_index, state_index, track_id)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             )\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtl_faces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;31m# 0,1,C -> C,0,1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\sampling\\agent_sampling.py\u001b[0m in \u001b[0;36mgenerate_agent_sample\u001b[1;34m(state_index, frames, agents, tl_faces, selected_track_id, render_context, history_num_frames, history_step_size, future_num_frames, future_step_size, filter_agents_threshold, rasterizer, perturbation)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrasterizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[1;32melse\u001b[0m \u001b[0mrasterizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrasterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_agents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_tl_faces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\rasterization\\sem_box_rasterizer.py\u001b[0m in \u001b[0;36mrasterize\u001b[1;34m(self, history_frames, history_agents, history_tl_faces, agent)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mim_out_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbox_rast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrasterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_agents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_tl_faces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mim_out_sat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msat_rast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrasterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_agents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_tl_faces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim_out_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_out_sat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\rasterization\\box_rasterizer.py\u001b[0m in \u001b[0;36mrasterize\u001b[1;34m(self, history_frames, history_agents, history_tl_faces, agent)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# add av to agents and remove the agent from agents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0magents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magents\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0magent_ego\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                     \u001b[0magents_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraster_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraster_from_world\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mav_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                     \u001b[0mego_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraster_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraster_from_world\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_ego\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\me\\anaconda3\\envs\\sdcar\\lib\\site-packages\\l5kit\\rasterization\\box_rasterizer.py\u001b[0m in \u001b[0;36mdraw_boxes\u001b[1;34m(raster_size, raster_from_world, agents, color)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# fillPoly wants polys in a sequence with points inside as (x,y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mbox_raster_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2_subpixel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox_raster_coords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillPoly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_raster_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCV2_SHIFT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==== TRAIN LOOP\n",
    "tr_it = iter(train_dataloader)\n",
    "vl_it = iter(val_dataloader)\n",
    "progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]), position=0)\n",
    "checkpoint_n = cfg[\"train_params\"][\"checkpoint_every_n_steps\"]\n",
    "losses_train = []\n",
    "curr_losses = []\n",
    "losses_avg = []\n",
    "hidden = None\n",
    "\n",
    "losses_val = []\n",
    "val_avg = []\n",
    "\n",
    "num_frames = 20\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    pred = model.forward(torch.flip(data['history_positions'], [1]).to(device), device)\n",
    "    \n",
    "    targets = data['target_positions'].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss = criterion(pred, targets)\n",
    "    loss = loss * target_availabilities\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses_train.append(loss.item())\n",
    "    curr_losses.append(loss.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            val_data = next(vl_it)\n",
    "        except StopIteration:\n",
    "            vl_it = iter(val_dataloader)\n",
    "            val_data = next(vl_it)\n",
    "\n",
    "        model.eval()\n",
    "        pred = model.forward(torch.flip(val_data['history_positions'], [1]).to(device), device)\n",
    "    \n",
    "        targets = val_data['target_positions'].to(device)\n",
    "        target_availabilities = val_data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "\n",
    "        # Backward pass\n",
    "        v_loss = criterion(pred, targets)\n",
    "        v_loss = v_loss * target_availabilities\n",
    "        v_loss = v_loss.mean()\n",
    "        losses_val.append(v_loss.item())\n",
    "        \n",
    "    if (i % checkpoint_n) == checkpoint_n - 1:\n",
    "#     if i % 2 == 1:\n",
    "        with open('Seq2Seq_LSTM_val.csv','a') as fd:\n",
    "            for loss in losses_val:\n",
    "                fd.write(f\"{i},{loss}\\n\")\n",
    "                \n",
    "        with open('Seq2Seq_LSTM_train.csv','a') as fd:\n",
    "            for loss in losses_train:\n",
    "                fd.write(f\"{i},{loss}\\n\")\n",
    "\n",
    "        train_avg_loss = np.mean(losses_train)\n",
    "        val_avg_loss =  np.mean(losses_val)\n",
    "        \n",
    "        losses_train = []\n",
    "        losses_val = []\n",
    "        \n",
    "        \n",
    "        with open('Seq2Seq_LSTM_train_avg.csv','a') as fd:\n",
    "            fd.write(f\"{i},{train_avg_loss}\\n\")\n",
    "            \n",
    "        with open('Seq2Seq_LSTM_val_avg.csv','a') as fd:\n",
    "            fd.write(f\"{i},{val_avg_loss}\\n\")\n",
    "        \n",
    "        progress_bar.set_description(f\"loss: {loss} loss(avg): {train_avg_loss} loss_val(avg): {val_avg_loss}\")\n",
    "        if (i+1) % 1000 == 0:\n",
    "            torch.save(model.state_dict(), f'Seq2Seq_LSTM_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame_Partial_LSTM9999\n",
    "train_cfg = cfg[\"test_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "FUTURE_NUM_FRAMES = cfg['model_params']['future_num_frames']\n",
    "SEQ_LEN = cfg['model_params']['history_num_frames'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "FUTURE_NUM_FRAMES = cfg['model_params']['future_num_frames']\n",
    "SEQ_LEN = cfg['model_params']['history_num_frames'] + 1\n",
    "\n",
    "model = Seq2Seq(hidden_size, 16, FUTURE_NUM_FRAMES, SEQ_LEN, FUTURE_NUM_FRAMES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "model.load_state_dict(torch.load('saved_models/Seq2Seq_LSTM_2999.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [21:17<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "tr_it = iter(train_dataloader)\n",
    "progress_bar = tqdm(range(1000), position=0)\n",
    "checkpoint_n = cfg[\"train_params\"][\"checkpoint_every_n_steps\"]\n",
    "losses_train = []\n",
    "curr_losses = []\n",
    "losses_avg = []\n",
    "\n",
    "losses_val = []\n",
    "val_avg = []\n",
    "\n",
    "hidden = None\n",
    "\n",
    "num_frames = 20\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    \n",
    "    # Train\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(torch.flip(data['history_positions'], [1]).to(device), device)\n",
    "    \n",
    "        targets = data['target_positions'].to(device)\n",
    "        target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "\n",
    "        # Backward pass\n",
    "        loss = criterion(pred, targets)\n",
    "        loss = loss * target_availabilities\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        losses_train.append(loss.item())\n",
    "    \n",
    "with open('Seq2Seq_LSTM_test.csv','a') as fd:\n",
    "    for loss in losses_train:\n",
    "        fd.write(f\"{i},{loss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss: 2.290573328493774\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Test Loss: {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
