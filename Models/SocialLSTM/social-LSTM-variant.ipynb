{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional-soical.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JqdK8ttE00Q"
      },
      "source": [
        "# **Utilits.py**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_qYPQiDEt8W"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import scipy.io as scp\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#___________________________________________________________________________________________________________________________\n",
        "\n",
        "class loadintoDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, mat_file, t_h=30, t_f=50, d_s=2, enc_size = 64, grid_size = (13,3)):\n",
        "        self.D = scp.loadmat(mat_file)['traj']\n",
        "        self.T = scp.loadmat(mat_file)['tracks']\n",
        "        self.t_h = t_h  # length of track history\n",
        "        self.t_f = t_f  # length of predicted trajectory\n",
        "        self.d_s = d_s  # down sampling rate of all sequences\n",
        "        self.enc_size = enc_size # size of encoder LSTM\n",
        "        self.grid_size = grid_size # size of social context grid\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.D)\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        dsId = self.D[idx, 0].astype(int)\n",
        "        vehId = self.D[idx, 1].astype(int)\n",
        "        t = self.D[idx, 2]\n",
        "        grid = self.D[idx,8:]\n",
        "        neighbors = []\n",
        "\n",
        "        # Get track history 'hist' = ndarray, and future track 'fut' = ndarray\n",
        "        hist = self.getHistory(vehId,t,vehId,dsId)\n",
        "        fut = self.getFuture(vehId,t,dsId)\n",
        "\n",
        "        # Get track histories of all neighbours 'neighbors' = [ndarray,[],ndarray,ndarray]\n",
        "        for i in grid:\n",
        "            neighbors.append(self.getHistory(i.astype(int), t,vehId,dsId))\n",
        "\n",
        "        lon_enc = np.zeros([2])\n",
        "        lon_enc[int(self.D[idx, 7] - 1)] = 1\n",
        "        lat_enc = np.zeros([3])\n",
        "        lat_enc[int(self.D[idx, 6] - 1)] = 1\n",
        "\n",
        "        return hist,fut,neighbors,lat_enc,lon_enc\n",
        "\n",
        "\n",
        "\n",
        "    def getHistory(self,vehId,t,refVehId,dsId):\n",
        "        if vehId == 0:\n",
        "            return np.empty([0,2])\n",
        "        else:\n",
        "            if self.T.shape[1]<=vehId-1:\n",
        "                return np.empty([0,2])\n",
        "            refTrack = self.T[dsId-1][refVehId-1].transpose()\n",
        "            vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
        "            refPos = refTrack[np.where(refTrack[:,0]==t)][0,1:3]\n",
        "\n",
        "            if vehTrack.size==0 or np.argwhere(vehTrack[:, 0] == t).size==0:\n",
        "                 return np.empty([0,2])\n",
        "            else:\n",
        "                stpt = np.maximum(0, np.argwhere(vehTrack[:, 0] == t).item() - self.t_h)\n",
        "                enpt = np.argwhere(vehTrack[:, 0] == t).item() + 1\n",
        "                hist = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
        "\n",
        "            if len(hist) < self.t_h//self.d_s + 1:\n",
        "                return np.empty([0,2])\n",
        "            return hist\n",
        "\n",
        "\n",
        "\n",
        "    def getFuture(self, vehId, t,dsId):\n",
        "        vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
        "        refPos = vehTrack[np.where(vehTrack[:, 0] == t)][0, 1:3]\n",
        "        stpt = np.argwhere(vehTrack[:, 0] == t).item() + self.d_s\n",
        "        enpt = np.minimum(len(vehTrack), np.argwhere(vehTrack[:, 0] == t).item() + self.t_f + 1)\n",
        "        fut = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
        "        return fut\n",
        "\n",
        "\n",
        "\n",
        "    ## Collate function for dataloader\n",
        "    def collate_fn(self, samples):\n",
        "\n",
        "        # Initialize neighbors and neighbors length batches:\n",
        "        nbr_batch_size = 0\n",
        "        for _,_,nbrs,_,_ in samples:\n",
        "            nbr_batch_size += sum([len(nbrs[i])!=0 for i in range(len(nbrs))])\n",
        "        maxlen = self.t_h//self.d_s + 1\n",
        "        nbrs_batch = torch.zeros(maxlen,nbr_batch_size,2)\n",
        "\n",
        "        pos = [0, 0]\n",
        "        mask_batch = torch.zeros(len(samples), self.grid_size[1],self.grid_size[0],self.enc_size)\n",
        "        mask_batch = mask_batch.byte()\n",
        "\n",
        "        hist_batch = torch.zeros(maxlen,len(samples),2)\n",
        "        fut_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
        "        op_mask_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
        "        lat_enc_batch = torch.zeros(len(samples),3)\n",
        "        lon_enc_batch = torch.zeros(len(samples), 2)\n",
        "\n",
        "\n",
        "        count = 0\n",
        "        for sampleId,(hist, fut, nbrs, lat_enc, lon_enc) in enumerate(samples):\n",
        "            hist_batch[0:len(hist),sampleId,0] = torch.from_numpy(hist[:, 0])\n",
        "            hist_batch[0:len(hist), sampleId, 1] = torch.from_numpy(hist[:, 1])\n",
        "            fut_batch[0:len(fut), sampleId, 0] = torch.from_numpy(fut[:, 0])\n",
        "            fut_batch[0:len(fut), sampleId, 1] = torch.from_numpy(fut[:, 1])\n",
        "            op_mask_batch[0:len(fut),sampleId,:] = 1\n",
        "            lat_enc_batch[sampleId,:] = torch.from_numpy(lat_enc)\n",
        "            lon_enc_batch[sampleId, :] = torch.from_numpy(lon_enc)\n",
        "\n",
        "            # Set up neighbor, neighbor sequence length, and mask batches:\n",
        "            for id,nbr in enumerate(nbrs):\n",
        "                if len(nbr)!=0:\n",
        "                    nbrs_batch[0:len(nbr),count,0] = torch.from_numpy(nbr[:, 0])\n",
        "                    nbrs_batch[0:len(nbr), count, 1] = torch.from_numpy(nbr[:, 1])\n",
        "                    pos[0] = id % self.grid_size[0]\n",
        "                    pos[1] = id // self.grid_size[0]\n",
        "                    mask_batch[sampleId,pos[1],pos[0],:] = torch.ones(self.enc_size).byte()\n",
        "                    count+=1\n",
        "\n",
        "        return hist_batch, nbrs_batch, mask_batch, lat_enc_batch, lon_enc_batch, fut_batch, op_mask_batch\n",
        "\n",
        "#________________________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "def outputActivation(x):\n",
        "    muX = x[:,:,0:1]\n",
        "    muY = x[:,:,1:2]\n",
        "    sigX = x[:,:,2:3]\n",
        "    sigY = x[:,:,3:4]\n",
        "    rho = x[:,:,4:5]\n",
        "    sigX = torch.exp(sigX)\n",
        "    sigY = torch.exp(sigY)\n",
        "    rho = torch.tanh(rho)\n",
        "    out = torch.cat([muX, muY, sigX, sigY, rho],dim=2)\n",
        "    return out\n",
        "\n",
        "def maskedNLL(y_pred, y_gt, mask):\n",
        "    acc = torch.zeros_like(mask)\n",
        "    muX = y_pred[:,:,0]\n",
        "    muY = y_pred[:,:,1]\n",
        "    sigX = y_pred[:,:,2]\n",
        "    sigY = y_pred[:,:,3]\n",
        "    rho = y_pred[:,:,4]\n",
        "    ohr = torch.pow(1-torch.pow(rho,2),-0.5)\n",
        "    x = y_gt[:,:, 0]\n",
        "    y = y_gt[:,:, 1]\n",
        "    out = 0.5*torch.pow(ohr, 2)*(torch.pow(sigX, 2)*torch.pow(x-muX, 2) + torch.pow(sigY, 2)*torch.pow(y-muY, 2) - 2*rho*torch.pow(sigX, 1)*torch.pow(sigY, 1)*(x-muX)*(y-muY)) - torch.log(sigX*sigY*ohr) + 1.8379\n",
        "    # out = 0.5 * torch.pow(ohr, 2) * (torch.pow(sigX, 2) * torch.pow(x - muX, 2) + torch.pow(sigY, 2) * torch.pow(y - muY, 2) - 2 * rho * torch.pow(sigX, 1) * torch.pow(sigY, 1) * (x - muX) * (y - muY)) - torch.log(sigX * sigY * ohr) + 1.8379 - 0.5160\n",
        "    acc[:,:,0] = out\n",
        "    acc[:,:,1] = out\n",
        "    acc = acc*mask\n",
        "    lossVal = torch.sum(acc)/torch.sum(mask)\n",
        "    return lossVal\n",
        "\n",
        "def maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, op_mask, num_lat_classes=3, num_lon_classes = 2,use_maneuvers = True, avg_along_time = False):\n",
        "    if use_maneuvers:\n",
        "        acc = torch.zeros(op_mask.shape[0],op_mask.shape[1],num_lon_classes*num_lat_classes).cuda()\n",
        "        count = 0\n",
        "        for k in range(num_lon_classes):\n",
        "            for l in range(num_lat_classes):\n",
        "                wts = lat_pred[:,l]*lon_pred[:,k]\n",
        "                wts = wts.repeat(len(fut_pred[0]),1)\n",
        "                y_pred = fut_pred[k*num_lat_classes + l]\n",
        "                y_gt = fut\n",
        "                muX = y_pred[:, :, 0]\n",
        "                muY = y_pred[:, :, 1]\n",
        "                sigX = y_pred[:, :, 2]\n",
        "                sigY = y_pred[:, :, 3]\n",
        "                rho = y_pred[:, :, 4]\n",
        "                ohr = torch.pow(1 - torch.pow(rho, 2), -0.5)\n",
        "                x = y_gt[:, :, 0]\n",
        "                y = y_gt[:, :, 1]\n",
        "                out = -(0.5*torch.pow(ohr, 2)*(torch.pow(sigX, 2)*torch.pow(x-muX, 2) + 0.5*torch.pow(sigY, 2)*torch.pow(y-muY, 2) - rho*torch.pow(sigX, 1)*torch.pow(sigY, 1)*(x-muX)*(y-muY)) - torch.log(sigX*sigY*ohr) + 1.8379)\n",
        "                # out = -(0.5 * torch.pow(ohr, 2) * (torch.pow(sigX, 2) * torch.pow(x - muX, 2) + torch.pow(sigY, 2) * torch.pow(y - muY, 2) - 2 * rho * torch.pow(sigX, 1) * torch.pow(sigY, 1) * (x - muX) * (y - muY)) - torch.log(sigX * sigY * ohr) + 1.8379 - 0.5160)\n",
        "                acc[:, :, count] =  out + torch.log(wts)\n",
        "                count+=1\n",
        "        acc = -logsumexp(acc, dim = 2)\n",
        "        acc = acc * op_mask[:,:,0]\n",
        "        if avg_along_time:\n",
        "            lossVal = torch.sum(acc) / torch.sum(op_mask[:, :, 0])\n",
        "            return lossVal\n",
        "        else:\n",
        "            lossVal = torch.sum(acc,dim=1)\n",
        "            counts = torch.sum(op_mask[:,:,0],dim=1)\n",
        "            return lossVal,counts\n",
        "    else:\n",
        "        acc = torch.zeros(op_mask.shape[0], op_mask.shape[1], 1).cuda()\n",
        "        y_pred = fut_pred\n",
        "        y_gt = fut\n",
        "        muX = y_pred[:, :, 0]\n",
        "        muY = y_pred[:, :, 1]\n",
        "        sigX = y_pred[:, :, 2]\n",
        "        sigY = y_pred[:, :, 3]\n",
        "        rho = y_pred[:, :, 4]\n",
        "        ohr = torch.pow(1 - torch.pow(rho, 2), -0.5)\n",
        "        x = y_gt[:, :, 0]\n",
        "        y = y_gt[:, :, 1]\n",
        "        out = 0.5*torch.pow(ohr, 2)*(torch.pow(sigX, 2)*torch.pow(x-muX, 2) + torch.pow(sigY, 2)*torch.pow(y-muY, 2) - 2 * rho*torch.pow(sigX, 1)*torch.pow(sigY, 1)*(x-muX)*(y-muY)) - torch.log(sigX*sigY*ohr) + 1.8379\n",
        "        acc[:, :, 0] = out\n",
        "        acc = acc * op_mask[:, :, 0:1]\n",
        "        if avg_along_time:\n",
        "            lossVal = torch.sum(acc[:, :, 0]) / torch.sum(op_mask[:, :, 0])\n",
        "            return lossVal\n",
        "        else:\n",
        "            lossVal = torch.sum(acc[:,:,0], dim=1)\n",
        "            counts = torch.sum(op_mask[:, :, 0], dim=1)\n",
        "            return lossVal,counts\n",
        "\n",
        "def maskedMSE(y_pred, y_gt, mask):\n",
        "    acc = torch.zeros_like(mask)\n",
        "    muX = y_pred[:,:,0]\n",
        "    muY = y_pred[:,:,1]\n",
        "    x = y_gt[:,:, 0]\n",
        "    y = y_gt[:,:, 1]\n",
        "    out = torch.pow(x-muX, 2) + torch.pow(y-muY, 2)\n",
        "    acc[:,:,0] = out\n",
        "    acc[:,:,1] = out\n",
        "    acc = acc*mask\n",
        "    lossVal = torch.sum(acc)/torch.sum(mask)\n",
        "    return lossVal\n",
        "\n",
        "def maskedMSETest(y_pred, y_gt, mask):\n",
        "    acc = torch.zeros_like(mask)\n",
        "    muX = y_pred[:, :, 0]\n",
        "    muY = y_pred[:, :, 1]\n",
        "    x = y_gt[:, :, 0]\n",
        "    y = y_gt[:, :, 1]\n",
        "    out = torch.pow(x - muX, 2) + torch.pow(y - muY, 2)\n",
        "    acc[:, :, 0] = out\n",
        "    acc[:, :, 1] = out\n",
        "    acc = acc * mask\n",
        "    lossVal = torch.sum(acc[:,:,0],dim=1)\n",
        "    counts = torch.sum(mask[:,:,0],dim=1)\n",
        "    return lossVal, counts\n",
        "\n",
        "def logsumexp(inputs, dim=None, keepdim=False):\n",
        "    if dim is None:\n",
        "        inputs = inputs.view(-1)\n",
        "        dim = 0\n",
        "    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n",
        "    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n",
        "    if not keepdim:\n",
        "        outputs = outputs.squeeze(dim)\n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgxVq6v5E6-T"
      },
      "source": [
        "# **Model.py**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhNLv9-PE7dM"
      },
      "source": [
        "from __future__ import division\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class sLSTMVariantNet(nn.Module):\n",
        "\n",
        "    ## Initialization\n",
        "    def __init__(self,args):\n",
        "        super(highwayNet, self).__init__()\n",
        "\n",
        "        ## Unpack arguments\n",
        "        self.args = args\n",
        "\n",
        "        ## Use gpu flag\n",
        "        self.use_cuda = args['use_cuda']\n",
        "\n",
        "        self.use_maneuvers = args['use_maneuvers']\n",
        "\n",
        "        self.train_flag = args['train_flag']\n",
        "\n",
        "        self.encoder_size = args['encoder_size']\n",
        "        self.decoder_size = args['decoder_size']\n",
        "        self.in_length = args['in_length']\n",
        "        self.out_length = args['out_length']\n",
        "        self.grid_size = args['grid_size']\n",
        "        self.soc_conv_depth = args['soc_conv_depth']\n",
        "        self.conv_3x1_depth = args['conv_3x1_depth']\n",
        "        self.dyn_embedding_size = args['dyn_embedding_size']\n",
        "        self.input_embedding_size = args['input_embedding_size']\n",
        "        self.num_lat_classes = args['num_lat_classes']\n",
        "        self.num_lon_classes = args['num_lon_classes']\n",
        "        self.soc_embedding_size = (((args['grid_size'][0]-4)+1)//2)*self.conv_3x1_depth\n",
        "\n",
        "\n",
        "        # Input embedding layer\n",
        "        self.ip_emb = torch.nn.Linear(2,self.input_embedding_size)\n",
        "\n",
        "        # Encoder LSTM\n",
        "        self.enc_lstm = torch.nn.LSTM(self.input_embedding_size,self.encoder_size,1)\n",
        "\n",
        "        # Vehicle dynamics embedding\n",
        "        self.dyn_emb = torch.nn.Linear(self.encoder_size,self.dyn_embedding_size)\n",
        "\n",
        "        # Convolutional social pooling layer and social embedding layer\n",
        "        self.soc_conv = torch.nn.Conv2d(self.encoder_size,self.soc_conv_depth,3)\n",
        "        self.conv_3x1 = torch.nn.Conv2d(self.soc_conv_depth, self.conv_3x1_depth, (3,1))\n",
        "        self.soc_maxpool = torch.nn.MaxPool2d((2,1),padding = (1,0))\n",
        "\n",
        "        # FC social pooling layer (for comparison):\n",
        "        # self.soc_fc = torch.nn.Linear(self.soc_conv_depth * self.grid_size[0] * self.grid_size[1], (((args['grid_size'][0]-4)+1)//2)*self.conv_3x1_depth)\n",
        "\n",
        "        # Decoder LSTM\n",
        "        if self.use_maneuvers:\n",
        "            self.dec_lstm = torch.nn.LSTM(self.soc_embedding_size + self.dyn_embedding_size + self.num_lat_classes + self.num_lon_classes, self.decoder_size)\n",
        "        else:\n",
        "            self.dec_lstm = torch.nn.LSTM(self.soc_embedding_size + self.dyn_embedding_size, self.decoder_size)\n",
        "\n",
        "        # Output layers:\n",
        "        self.op = torch.nn.Linear(self.decoder_size,5)\n",
        "        self.op_lat = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lat_classes)\n",
        "        self.op_lon = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lon_classes)\n",
        "\n",
        "        # Activations:\n",
        "        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    ## Forward Pass\n",
        "    def forward(self,hist,nbrs,masks,lat_enc,lon_enc):\n",
        "\n",
        "        ## Forward pass hist:\n",
        "        _,(hist_enc,_) = self.enc_lstm(self.leaky_relu(self.ip_emb(hist)))\n",
        "        hist_enc = self.leaky_relu(self.dyn_emb(hist_enc.view(hist_enc.shape[1],hist_enc.shape[2])))\n",
        "\n",
        "        ## Forward pass nbrs\n",
        "        _, (nbrs_enc,_) = self.enc_lstm(self.leaky_relu(self.ip_emb(nbrs)))\n",
        "        nbrs_enc = nbrs_enc.view(nbrs_enc.shape[1], nbrs_enc.shape[2])\n",
        "\n",
        "        ## Masked scatter\n",
        "        soc_enc = torch.zeros_like(masks).float()\n",
        "        soc_enc = soc_enc.masked_scatter_(masks, nbrs_enc)\n",
        "        soc_enc = soc_enc.permute(0,3,2,1)\n",
        "\n",
        "        ## Apply convolutional social pooling:\n",
        "        soc_enc = self.soc_maxpool(self.leaky_relu(self.conv_3x1(self.leaky_relu(self.soc_conv(soc_enc)))))\n",
        "        soc_enc = soc_enc.view(-1,self.soc_embedding_size)\n",
        "\n",
        "        ## Concatenate encodings:\n",
        "        enc = torch.cat((soc_enc,hist_enc),1)\n",
        "\n",
        "\n",
        "        if self.use_maneuvers:\n",
        "            ## Maneuver recognition:\n",
        "            lat_pred = self.softmax(self.op_lat(enc))\n",
        "            lon_pred = self.softmax(self.op_lon(enc))\n",
        "\n",
        "            if self.train_flag:\n",
        "                ## Concatenate maneuver encoding of the true maneuver\n",
        "                enc = torch.cat((enc, lat_enc, lon_enc), 1)\n",
        "                fut_pred = self.decode(enc)\n",
        "                return fut_pred, lat_pred, lon_pred\n",
        "            else:\n",
        "                fut_pred = []\n",
        "                ## Predict trajectory distributions for each maneuver class\n",
        "                for k in range(self.num_lon_classes):\n",
        "                    for l in range(self.num_lat_classes):\n",
        "                        lat_enc_tmp = torch.zeros_like(lat_enc)\n",
        "                        lon_enc_tmp = torch.zeros_like(lon_enc)\n",
        "                        lat_enc_tmp[:, l] = 1\n",
        "                        lon_enc_tmp[:, k] = 1\n",
        "                        enc_tmp = torch.cat((enc, lat_enc_tmp, lon_enc_tmp), 1)\n",
        "                        fut_pred.append(self.decode(enc_tmp))\n",
        "                return fut_pred, lat_pred, lon_pred\n",
        "        else:\n",
        "            fut_pred = self.decode(enc)\n",
        "            return fut_pred\n",
        "\n",
        "\n",
        "    def decode(self,enc):\n",
        "        enc = enc.repeat(self.out_length, 1, 1)\n",
        "        h_dec, _ = self.dec_lstm(enc)\n",
        "        h_dec = h_dec.permute(1, 0, 2)\n",
        "        fut_pred = self.op(h_dec)\n",
        "        fut_pred = fut_pred.permute(1, 0, 2)\n",
        "        fut_pred = outputActivation(fut_pred)\n",
        "        return fut_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptq3Xx6hFLQv"
      },
      "source": [
        "# **Train.py**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD3lqDUoFLqb"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "## Network Arguments\n",
        "args = {}\n",
        "args['use_cuda'] = True\n",
        "args['encoder_size'] = 64\n",
        "args['decoder_size'] = 128\n",
        "args['in_length'] = 16\n",
        "args['out_length'] = 25\n",
        "args['grid_size'] = (13,3)\n",
        "args['soc_conv_depth'] = 64\n",
        "args['conv_3x1_depth'] = 16\n",
        "args['dyn_embedding_size'] = 32\n",
        "args['input_embedding_size'] = 32\n",
        "args['num_lat_classes'] = 3\n",
        "args['num_lon_classes'] = 2\n",
        "args['use_maneuvers'] = True\n",
        "args['train_flag'] = True\n",
        "\n",
        "\n",
        "\n",
        "# Initialize network\n",
        "net = sLSTMVariantNet(args)\n",
        "if args['use_cuda']:\n",
        "    net = net.cuda()\n",
        "\n",
        "\n",
        "## Initialize optimizer\n",
        "pretrainEpochs = 5\n",
        "trainEpochs = 0\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "batch_size = 128\n",
        "crossEnt = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "## Initialize data loaders\n",
        "trSet = loadintoDataset('data/TrainSet.mat')\n",
        "valSet = loadintoDataset('data/ValSet.mat')\n",
        "trDataloader = DataLoader(trSet,batch_size=batch_size,shuffle=True,num_workers=8,collate_fn=trSet.collate_fn)\n",
        "valDataloader = DataLoader(valSet,batch_size=batch_size,shuffle=True,num_workers=8,collate_fn=valSet.collate_fn)\n",
        "\n",
        "\n",
        "## Variables holding train and validation loss values:\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "prev_val_loss = math.inf\n",
        "\n",
        "for epoch_num in range(pretrainEpochs+trainEpochs):\n",
        "    if epoch_num == 0:\n",
        "        print('Pre-training with MSE loss')\n",
        "    elif epoch_num == pretrainEpochs:\n",
        "        print('Training with NLL loss')\n",
        "\n",
        "\n",
        "    ## Train:_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "    net.train_flag = True\n",
        "\n",
        "    # Variables to track training performance:\n",
        "    avg_tr_loss = 0\n",
        "    avg_tr_time = 0\n",
        "    avg_lat_acc = 0\n",
        "    avg_lon_acc = 0\n",
        "\n",
        "\n",
        "    for i, data in enumerate(trDataloader):\n",
        "\n",
        "        st_time = time.time()\n",
        "        hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "\n",
        "        if args['use_cuda']:\n",
        "            hist = hist.cuda()\n",
        "            nbrs = nbrs.cuda()\n",
        "            mask = mask.cuda()\n",
        "            lat_enc = lat_enc.cuda()\n",
        "            lon_enc = lon_enc.cuda()\n",
        "            fut = fut.cuda()\n",
        "            op_mask = op_mask.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        if args['use_maneuvers']:\n",
        "            fut_pred, lat_pred, lon_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            if epoch_num < pretrainEpochs:\n",
        "                l = maskedMSE(fut_pred, fut, op_mask)\n",
        "            else:\n",
        "                l = maskedNLL(fut_pred, fut, op_mask) + crossEnt(lat_pred, lat_enc) + crossEnt(lon_pred, lon_enc)\n",
        "                avg_lat_acc += (torch.sum(torch.max(lat_pred.data, 1)[1] == torch.max(lat_enc.data, 1)[1])).item() / lat_enc.size()[0]\n",
        "                avg_lon_acc += (torch.sum(torch.max(lon_pred.data, 1)[1] == torch.max(lon_enc.data, 1)[1])).item() / lon_enc.size()[0]\n",
        "        else:\n",
        "            fut_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            if epoch_num < pretrainEpochs:\n",
        "                l = maskedMSE(fut_pred, fut, op_mask)\n",
        "            else:\n",
        "                l = maskedNLL(fut_pred, fut, op_mask)\n",
        "\n",
        "        # Backprop and update weights\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        a = torch.nn.utils.clip_grad_norm_(net.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track average train loss and average train time:\n",
        "        batch_time = time.time()-st_time\n",
        "        avg_tr_loss += l.item()\n",
        "        avg_tr_time += batch_time\n",
        "\n",
        "        if i%100 == 99:\n",
        "            eta = avg_tr_time/100*(len(trSet)/batch_size-i)\n",
        "            print(\"Epoch no:\",epoch_num+1,\"| Epoch progress(%):\",format(i/(len(trSet)/batch_size)*100,'0.2f'), \"| Avg train loss:\",format(avg_tr_loss/100,'0.4f'),\"| Acc:\",format(avg_lat_acc,'0.4f'),format(avg_lon_acc,'0.4f'), \"| Validation loss prev epoch\",format(prev_val_loss,'0.4f'), \"| ETA(s):\",int(eta))\n",
        "            train_loss.append(avg_tr_loss/100)\n",
        "            avg_tr_loss = 0\n",
        "            avg_lat_acc = 0\n",
        "            avg_lon_acc = 0\n",
        "            avg_tr_time = 0\n",
        "    # _________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "    ## Validate:______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "    net.train_flag = False\n",
        "\n",
        "    print(\"Epoch\",epoch_num+1,'complete. Calculating validation loss...')\n",
        "    avg_val_loss = 0\n",
        "    avg_val_lat_acc = 0\n",
        "    avg_val_lon_acc = 0\n",
        "    val_batch_count = 0\n",
        "    total_points = 0\n",
        "\n",
        "    for i, data  in enumerate(valDataloader):\n",
        "        st_time = time.time()\n",
        "        hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "\n",
        "\n",
        "        if args['use_cuda']:\n",
        "            hist = hist.cuda()\n",
        "            nbrs = nbrs.cuda()\n",
        "            mask = mask.cuda()\n",
        "            lat_enc = lat_enc.cuda()\n",
        "            lon_enc = lon_enc.cuda()\n",
        "            fut = fut.cuda()\n",
        "            op_mask = op_mask.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        if args['use_maneuvers']:\n",
        "            if epoch_num < pretrainEpochs:\n",
        "                # During pre-training with MSE loss, validate with MSE for true maneuver class trajectory\n",
        "                net.train_flag = True\n",
        "                fut_pred, _ , _ = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                l = maskedMSE(fut_pred, fut, op_mask)\n",
        "            else:\n",
        "                # During training with NLL loss, validate with NLL over multi-modal distribution\n",
        "                fut_pred, lat_pred, lon_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                l = maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, op_mask,avg_along_time = True)\n",
        "                avg_val_lat_acc += (torch.sum(torch.max(lat_pred.data, 1)[1] == torch.max(lat_enc.data, 1)[1])).item() / lat_enc.size()[0]\n",
        "                avg_val_lon_acc += (torch.sum(torch.max(lon_pred.data, 1)[1] == torch.max(lon_enc.data, 1)[1])).item() / lon_enc.size()[0]\n",
        "        else:\n",
        "            fut_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            if epoch_num < pretrainEpochs:\n",
        "                l = maskedMSE(fut_pred, fut, op_mask)\n",
        "            else:\n",
        "                l = maskedNLL(fut_pred, fut, op_mask)\n",
        "\n",
        "        avg_val_loss += l.item()\n",
        "        val_batch_count += 1\n",
        "\n",
        "    print(avg_val_loss/val_batch_count)\n",
        "\n",
        "    # Print validation loss and update display variables\n",
        "    print('Validation loss :',format(avg_val_loss/val_batch_count,'0.4f'),\"| Val Acc:\",format(avg_val_lat_acc/val_batch_count*100,'0.4f'),format(avg_val_lon_acc/val_batch_count*100,'0.4f'))\n",
        "    val_loss.append(avg_val_loss/val_batch_count)\n",
        "    prev_val_loss = avg_val_loss/val_batch_count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "torch.save(net.state_dict(), 'trained_models/cslstm_m.tar')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHETB1LjFY5K"
      },
      "source": [
        "# **Evaluate.py**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdB1TprQFYoG"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "## Network Arguments\n",
        "args = {}\n",
        "args['use_cuda'] = True\n",
        "args['encoder_size'] = 64\n",
        "args['decoder_size'] = 128\n",
        "args['in_length'] = 16\n",
        "args['out_length'] = 25\n",
        "args['grid_size'] = (13,3)\n",
        "args['soc_conv_depth'] = 64\n",
        "args['conv_3x1_depth'] = 16\n",
        "args['dyn_embedding_size'] = 32\n",
        "args['input_embedding_size'] = 32\n",
        "args['num_lat_classes'] = 3\n",
        "args['num_lon_classes'] = 2\n",
        "args['use_maneuvers'] = True\n",
        "args['train_flag'] = False\n",
        "\n",
        "\n",
        "# Evaluation metric:\n",
        "#metric = 'nll'  #or rmse\n",
        "metric = 'rmse'\n",
        "\n",
        "\n",
        "# Initialize network\n",
        "net = sLSTMVariantNet(args)\n",
        "\n",
        "net.load_state_dict(torch.load('trained_models/cslstm_m.tar'))\n",
        "\n",
        "if args['use_cuda']:\n",
        "    net = net.cuda()\n",
        "\n",
        "tsSet = loadintoDataset('data/TestSet.mat')\n",
        "tsDataloader = DataLoader(tsSet,batch_size=128,shuffle=True,num_workers=8,collate_fn=tsSet.collate_fn)\n",
        "\n",
        "lossVals = torch.zeros(25).cuda()\n",
        "counts = torch.zeros(25).cuda()\n",
        "\n",
        "epoch_num = 1\n",
        "\n",
        "print(\"Epoch\",epoch_num,'complete. Calculating validation loss...')\n",
        "avg_val_loss = 0\n",
        "avg_val_lat_acc = 0\n",
        "avg_val_lon_acc = 0\n",
        "val_batch_count = 0\n",
        "total_points = 0\n",
        "\n",
        "\n",
        "for i, data in enumerate(tsDataloader):\n",
        "    st_time = time.time()\n",
        "    hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "\n",
        "    # Initialize Variables\n",
        "    if args['use_cuda']:\n",
        "        hist = hist.cuda()\n",
        "        nbrs = nbrs.cuda()\n",
        "        mask = mask.cuda()\n",
        "        lat_enc = lat_enc.cuda()\n",
        "        lon_enc = lon_enc.cuda()\n",
        "        fut = fut.cuda()\n",
        "        op_mask = op_mask.cuda()\n",
        "\n",
        "    if metric == 'nll':\n",
        "        # Forward pass\n",
        "        if args['use_maneuvers']:\n",
        "            fut_pred, lat_pred, lon_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            l,c = maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, op_mask)\n",
        "        else:\n",
        "            fut_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            l, c = maskedNLLTest(fut_pred, 0, 0, fut, op_mask,use_maneuvers=False)\n",
        "    else:\n",
        "        # Forward pass\n",
        "        if args['use_maneuvers']:\n",
        "            #fut_pred, lat_pred, lon_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            net.train_flag = True\n",
        "\n",
        "            fut_pred,_,_ = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "\n",
        "            l = maskedMSE(fut_pred, fut, op_mask)\n",
        "\n",
        "            \"\"\"\n",
        "            fut_pred_max = torch.zeros_like(fut_pred[0])\n",
        "            for k in range(lat_pred.shape[0]):\n",
        "                lat_man = torch.argmax(lat_pred[k, :]).detach()\n",
        "                lon_man = torch.argmax(lon_pred[k, :]).detach()\n",
        "                indx = lon_man*3 + lat_man\n",
        "                fut_pred_max[:,k,:] = fut_pred[indx][:,k,:]\n",
        "            l, c = maskedMSETest(fut_pred_max, fut, op_mask)\n",
        "            \"\"\"\n",
        "        else:\n",
        "            fut_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "            l, c = maskedMSETest(fut_pred, fut, op_mask)\n",
        "\n",
        "    avg_val_loss += l.item()\n",
        "    val_batch_count += 1\n",
        "\n",
        "    #lossVals +=l.detach()\n",
        "    #counts += c.detach()\n",
        "\n",
        "\n",
        "print(avg_val_loss/val_batch_count)\n",
        "\n",
        "# Print validation loss and update display variables\n",
        "print('Validation loss :',format(avg_val_loss/val_batch_count,'0.4f'),\"| Val Acc:\",format(avg_val_lat_acc/val_batch_count*100,'0.4f'),format(avg_val_lon_acc/val_batch_count*100,'0.4f'))\n",
        "val_loss.append(avg_val_loss/val_batch_count)\n",
        "prev_val_loss = avg_val_loss/val_batch_count\n",
        "\n",
        "\"\"\"\n",
        "if metric == 'nll':\n",
        "    print(lossVals / counts)\n",
        "else:\n",
        "    print(torch.pow(lossVals / counts,0.5)*0.3048)   # Calculate RMSE and convert from feet to meters\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}