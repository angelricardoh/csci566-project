{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet18,resnet50,resnet101\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "from torch import functional as F\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_INPUT = \"../../../lyft/data/lyft-motion-prediction-autonomous-vehicles\"\n",
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)\n",
    "VALIDATION = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18',\n",
    "        \n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        \n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "    \n",
    "    'raster_params': {\n",
    "        'raster_size': [1, 1],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5,\n",
    "        'disable_traffic_light_faces': True\n",
    "    },\n",
    "    \n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'val_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "    \n",
    "    'train_params': {\n",
    "        'checkpoint_every_n_steps': 5000,\n",
    "        'max_num_steps': 10000,\n",
    "        'eval_every_n_steps': 500\n",
    "\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ERROR ! ##\n",
    "import gc\n",
    "\n",
    "val_cfg = cfg[\"val_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "val_zarr = ChunkedDataset(dm.require(val_cfg[\"key\"])).open()\n",
    "val_dataset = AgentDataset(cfg, val_zarr, rasterizer)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                              shuffle=val_cfg[\"shuffle\"],\n",
    "                              batch_size=val_cfg[\"batch_size\"],\n",
    "                              num_workers=val_cfg[\"num_workers\"])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle=train_cfg[\"shuffle\"],\n",
    "                              batch_size=train_cfg[\"batch_size\"],\n",
    "                              num_workers=train_cfg[\"num_workers\"])\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# ===== INIT DATASET\n",
    "test_cfg = cfg[\"test_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# Train dataset/dataloader\n",
    "test_zarr = ChunkedDataset(dm.require(test_cfg[\"key\"])).open()\n",
    "test_dataset = AgentDataset(cfg, test_zarr, rasterizer)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              shuffle=test_cfg[\"shuffle\"],\n",
    "                              batch_size=test_cfg[\"batch_size\"],\n",
    "                              num_workers=test_cfg[\"num_workers\"])\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Seq-to-Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM_LyftModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super(EncoderLSTM_LyftModel, self).__init__()\n",
    "        \n",
    "        self.input_sz  = 3\n",
    "        self.hidden_sz = 128\n",
    "        self.num_layer = 1\n",
    "        self.sequence_length = 11        \n",
    "        \n",
    "        self.Encoder_lstm = nn.LSTM(self.input_sz,self.hidden_sz,self.num_layer,batch_first=True)\n",
    "       \n",
    "    def forward(self,inputs):\n",
    "        '''\n",
    "        Implemented Encoder with LSTM to extract \n",
    "        temporal information on history trajectories\n",
    "        '''\n",
    "        \n",
    "        output,hidden_state = self.Encoder_lstm(inputs)\n",
    "        \n",
    "        return output,hidden_state\n",
    "    \n",
    "class DecoderLSTM_LyftModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DecoderLSTM_LyftModel, self).__init__()\n",
    "        \n",
    "        self.input_sz  = 128 \n",
    "        self.hidden_sz = 128\n",
    "        self.num_layer = 1\n",
    "        self.sequence_len_de = 1\n",
    "        self.batch_sz = 32\n",
    "        \n",
    "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        \n",
    "        self.encoderLSTM = EncoderLSTM_LyftModel(cfg)\n",
    "\n",
    "        \n",
    "        self.Decoder_lstm = nn.LSTM( self.input_sz,self.hidden_sz,self.num_layer,batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        '''\n",
    "        With last hidden state, cell state trained on encoder, \n",
    "        predict 50 future trajectories with LSTM.\n",
    "        Input to the decoder is zero vector of shape (batch_sz, 50, 128) \n",
    "        since most of the current position is at 0\n",
    "        '''\n",
    "        \n",
    "        # Last hidden state and cell state on encoder        \n",
    "        _,hidden_state = self.encoderLSTM(inputs)\n",
    "        \n",
    "        # Dummy future trajectories        \n",
    "        result = torch.zeros((self.batch_sz, 50, 128))\n",
    "        \n",
    "        # Input to decoder        \n",
    "        inout_to_dec = torch.zeros(inputs.shape[0],self.sequence_len_de,self.input_sz).to(device)\n",
    "\n",
    "        # Predict 50 future trajectories consecutively        \n",
    "        for i in range(50):\n",
    "            inout_to_dec,hidden_state = self.Decoder_lstm(inout_to_dec,(hidden_state[0],hidden_state[1]) )          \n",
    "            result[:,i,:] = inout_to_dec[:,0,:]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, starting_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_sz  = 128 # hidden state size from seq-to-seq\n",
    "        self.hidden_sz = 256         \n",
    "        self.num_layer = 1\n",
    "        self.sequence_len_de = 1\n",
    "        self.interlayer = 512\n",
    "        self.DecoderLSTM_LyftModel = DecoderLSTM_LyftModel(cfg)\n",
    "        \n",
    "        num_targets = 2\n",
    "        \n",
    "        self.fcn_en_state_dec_state = nn.Sequential(nn.Linear(in_features=self.hidden_sz, out_features=self.hidden_sz),\n",
    "                                                    nn.ReLU(inplace=True),\n",
    "                                                    nn.Linear(in_features = self.hidden_sz, out_features = self.interlayer),\n",
    "                                                    nn.ReLU(inplace=True),\n",
    "                                                    nn.Linear(in_features = self.interlayer, out_features = self.hidden_sz),\n",
    "                                                    nn.ReLU(inplace=True),\n",
    "                                                    nn.Linear(in_features=self.hidden_sz, out_features=num_targets))\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        '''\n",
    "        With latent temporal vector from decoder, \n",
    "        add noise to the generator and generate\n",
    "        50 future trajectories of each agents\n",
    "        '''\n",
    "        \n",
    "        # Temporal vector from decoder        \n",
    "        decoderLSTM = self.DecoderLSTM_LyftModel(inputs)\n",
    "        \n",
    "        # Noise from Gaussian Distribution        \n",
    "        noise_gen = torch.randn(decoderLSTM.shape, device=device) \n",
    "        \n",
    "        # Add noise to the latent vector        \n",
    "        combine = torch.cat([decoderLSTM, noise_gen], dim = 2)\n",
    "        \n",
    "        # Generate Trajectories        \n",
    "        fc_out = self.fcn_en_state_dec_state(combine.squeeze(dim=0))\n",
    "        return fc_out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator with Relu\n",
    "class Discriminator_0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input = 100\n",
    "        self.lstm_hidden = 128\n",
    "        self.hidden_sz_1 = 6400\n",
    "        self.hidden_sz_2 = 3200\n",
    "        self.hidden_sz_3 = 1600\n",
    "        self.hidden_sz_4 = 800\n",
    "\n",
    "        \n",
    "        self.input_sz = 2\n",
    "        self.num_layer = 1\n",
    "        self.batch_sz = 32\n",
    "        self.fc= nn.Sequential(\n",
    "            nn.Linear(in_features=self.hidden_sz_1, out_features=self.hidden_sz_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.hidden_sz_2, out_features=self.hidden_sz_3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.hidden_sz_3, out_features=self.hidden_sz_4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.hidden_sz_4, out_features=1)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(self.input_sz,self.lstm_hidden,self.num_layer,batch_first=True)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output, _ = self.lstm(input)\n",
    "        output = output.reshape((self.batch_sz, -1))\n",
    "        fc = self.fc(output)\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator with WeakyRelu, dropout, and batch norm\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.input_sz = 2\n",
    "        self.num_layer = 1\n",
    "        self.batch_sz = 32        \n",
    "        self.lstm_hidden = 128\n",
    "        \n",
    "        self.hidden_sz_1 = 6400\n",
    "        self.hidden_sz_2 = 3200\n",
    "        self.hidden_sz_3 = 1600\n",
    "        self.hidden_sz_4 = 800\n",
    "        \n",
    "        self.fc= nn.Sequential(\n",
    "            nn.Linear(in_features=self.hidden_sz_1, out_features=self.hidden_sz_2),\n",
    "            nn.BatchNorm1d(self.hidden_sz_2),            \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=self.hidden_sz_2, out_features=self.hidden_sz_3),            \n",
    "            nn.BatchNorm1d(self.hidden_sz_3),                        \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),            \n",
    "            nn.Linear(in_features=self.hidden_sz_3, out_features=self.hidden_sz_4),\n",
    "            nn.BatchNorm1d(self.hidden_sz_4),                                    \n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.5),            \n",
    "            nn.Linear(in_features=self.hidden_sz_4, out_features=1)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(self.input_sz,self.lstm_hidden,self.num_layer,batch_first=True)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Input to the discriminator is either real trajectory or\n",
    "        generated fake trajectory. Discriminator would differentiate\n",
    "        if trajectories are real/fake with LSTM and FC\n",
    "        '''                \n",
    "        output, _ = self.lstm(input)\n",
    "        output = output.reshape((self.batch_sz, -1))\n",
    "        fc = self.fc(output)\n",
    "        return fc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to put tensors on GPU/CPU automatically when defining tensors\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "class GAN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GAN, self).__init__()\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 32\n",
    "        self.log_step = 100\n",
    "        self.visualize_step = 1\n",
    "        self.code_size = 64\n",
    "        self.learning_rate = 1e-3\n",
    "        self.val = 100\n",
    "        \n",
    "        # Define L2 Loss for the generator        \n",
    "        self._l2_loss = nn.MSELoss()\n",
    "\n",
    "        \n",
    "        # Define the generator and both discriminator \n",
    "        self._discriminator = Discriminator().to(device)\n",
    "        self._generator = Generator(self.code_size).to(device)\n",
    "\n",
    "        # Loss function for the discriminator        \n",
    "        self._classification_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Apply weight initialization here\n",
    "        self._discriminator.apply(self._weight_initialization)\n",
    "        self._generator.apply(self._weight_initialization)\n",
    "\n",
    "        # Hyper parameter for the Adam Optimizer\n",
    "        betas = (0.5, 0.999)\n",
    "        \n",
    "        # Optimizer for Generator and Discriminator        \n",
    "        self._generator_optimizer = torch.optim.Adam(self._generator.parameters(), lr = self.learning_rate, betas = betas)\n",
    "        self._discriminator_optimizer = torch.optim.Adam(self._discriminator.parameters(), lr = self.learning_rate, betas = betas)\n",
    "\n",
    "    # custom weights initialization for both networks\n",
    "    # apply the custom weight initialization\n",
    "        \n",
    "    def _weight_initialization(self, m):\n",
    "        # custom weights initialization for both networks\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    # Discriminator Loss            \n",
    "    def _loss(self, logits, labels):\n",
    "        return self._classification_loss(logits, labels)\n",
    "\n",
    "    # Generator Loss    \n",
    "    def _reconstruction_loss(self, generated, target):\n",
    "        return self._l2_loss(generated, target)\n",
    "\n",
    "    # Training function\n",
    "    def forward(self, train_dataloader):\n",
    "        for epoch in range(self.num_epoch):\n",
    "            # Save train loss for discriminator and generator        \n",
    "            dis_losses = []\n",
    "            gen_losses = []\n",
    "            \n",
    "            # Save validation loss for discriminator and generator                    \n",
    "            val_dis_losses = []\n",
    "            val_gen_losses = []\n",
    "            \n",
    "            step = 0\n",
    "\n",
    "            # smooth the loss curve so that it does not fluctuate too much\n",
    "            smooth_factor = 0.95\n",
    "            plot_dis_s = 0\n",
    "            plot_gen_s = 0\n",
    "            plot_ws = 0\n",
    "\n",
    "\n",
    "            max_steps = int(len(iter(train_dataloader)))\n",
    "            \n",
    "            # Fake label for discriminator            \n",
    "            fake_label = torch.zeros([self.batch_size, 1], device=device)\n",
    "            \n",
    "            # Real label for discriminator                        \n",
    "            real_label = torch.ones([self.batch_size, 1], device=device)\n",
    "            \n",
    "            print('Start training ...')\n",
    "\n",
    "            progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]))\n",
    "\n",
    "            tr_it = iter(train_dataloader)\n",
    "\n",
    "            \n",
    "            for itr in progress_bar:\n",
    "                try:\n",
    "                    data = next(tr_it)\n",
    "                except StopIteration:\n",
    "                    tr_it = iter(train_dataloader)\n",
    "                    data = next(tr_it)\n",
    "                step += 1\n",
    "                \n",
    "                # Train generator and discriminator                \n",
    "                gan.train()\n",
    "                self._generator.train()\n",
    "                self._discriminator.train()\n",
    "\n",
    "                \n",
    "                ################################################################################\n",
    "                # Train the discriminator                                                      #\n",
    "                ################################################################################\n",
    "                history_positions = torch.flip(data['history_positions'], [1]).to(device)\n",
    "                history_yaws = torch.flip(data['history_yaws'], [1])\n",
    "                history_availabilities = data['history_availabilities'].to(device)\n",
    "                history_pos_yaws = torch.cat([history_positions, history_yaws], dim = 2).to(device)\n",
    "\n",
    "                target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "                targets_position = data[\"target_positions\"].to(device) \n",
    "                \n",
    "                # Eliminate discriminator gradients\n",
    "                self._discriminator_optimizer.zero_grad()\n",
    "\n",
    "                # Calculate BCE loss on discriminator\n",
    "                real_dis_out = self._discriminator(targets_position)\n",
    "                real_dis_loss = self._loss(real_dis_out, real_label)\n",
    "\n",
    "                # Calculate real discriminator loss gradients\n",
    "                real_dis_loss.backward()\n",
    "\n",
    "                ################################################################################\n",
    "                # Train the discriminator with an all fake batch                               #\n",
    "                ################################################################################\n",
    "                # Detach the fake samples from the gradient calculation \n",
    "                # when feeding to the discriminator, we don't want the discriminator to \n",
    "                # receive gradient info from the Generator\n",
    "\n",
    "                fake_samples = self._generator(history_pos_yaws).detach()\n",
    "                fake_dis_out = self._discriminator(fake_samples)\n",
    "                \n",
    "                numGenerated = fake_dis_out.shape[0]\n",
    "\n",
    "                fake_dis_label = fake_label[:numGenerated] \n",
    "                fake_dis_loss = self._loss(fake_dis_out, fake_dis_label).requires_grad_()\n",
    "\n",
    "\n",
    "                # Calculate fake discriminator loss gradients\n",
    "                fake_dis_loss.backward()\n",
    "                \n",
    "                # Update the discriminator weights                                \n",
    "                self._discriminator_optimizer.step()\n",
    "\n",
    "                ################################################################################\n",
    "                # Train the generator                                                          #\n",
    "                ################################################################################                \n",
    "                # Get new samples from updated discriminator. No need to detach\n",
    "                # from gradient calculation here, we want the Generator to receive\n",
    "                # gradient info from the discriminator so it can learn better.\n",
    "\n",
    "                # Eliminate all generator gradients first\n",
    "\n",
    "                self._generator_optimizer.zero_grad()\n",
    "\n",
    "                # Generate future trajectories with history positions\n",
    "                fake_samples_gen = self._generator(history_pos_yaws)\n",
    "\n",
    "\n",
    "                fake_dis_out_gen = self._discriminator(fake_samples_gen)\n",
    "\n",
    "                generated_Num = fake_dis_out_gen.shape[0]\n",
    "\n",
    "                # Calculate the generator loss gradients\n",
    "                gen_loss = self._loss(fake_dis_out_gen, real_label[:generated_Num])\n",
    "                gen_loss.backward()\n",
    "                \n",
    "                # Update the generator weights                \n",
    "                self._generator_optimizer.step()\n",
    "\n",
    "                # Add up discriminator loss                \n",
    "                dis_loss = real_dis_loss + fake_dis_loss\n",
    "\n",
    "                # Apply smoothing factors for the plot                \n",
    "                plot_dis_s = plot_dis_s * smooth_factor + dis_loss * (1 - smooth_factor)\n",
    "                plot_gen_s = plot_gen_s * smooth_factor + gen_loss * (1 - smooth_factor)\n",
    "                plot_ws = plot_ws * smooth_factor + (1 - smooth_factor)\n",
    "                \n",
    "                dis_losses.append(plot_dis_s / plot_ws)\n",
    "                gen_losses.append(plot_gen_s / plot_ws)\n",
    "\n",
    "                # Validation\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    try:\n",
    "                        val_data = next(vl_it)\n",
    "                    except:\n",
    "                        vl_it = iter(val_dataloader)\n",
    "                        val_data = next(vl_it)\n",
    "                        \n",
    "                    gan.eval()\n",
    "                    self._generator.eval()\n",
    "                    self._discriminator.eval()\n",
    "                    \n",
    "                    # Fetch Validation data                    \n",
    "                    val_history_positions = torch.flip(val_data['history_positions'], [1]).to(device)\n",
    "                    val_history_yaws = torch.flip(val_data['history_yaws'], [1]).to(device)\n",
    "                    \n",
    "#                     val_history_availabilities = torch.flip(val_data['history_availabilities'], [1]).to(device)\n",
    "                    val_target_availabilities = val_data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "                    val_targets_position = val_data[\"target_positions\"].to(device)\n",
    "                    val_history_pos_yaws = torch.cat([val_history_positions, val_history_yaws], dim = 2).to(device)\n",
    "\n",
    "                    # Calculate Validation loss of discriminator\n",
    "                    val_real_dis_out = self._discriminator(val_targets_position)\n",
    "                    val_real_dis_loss = self._loss(val_real_dis_out, real_label)\n",
    "\n",
    "                    # Calculate Validation loss of generator            \n",
    "                    val_fake_samples_gen = self._generator(val_history_pos_yaws)\n",
    "                    val_gen_loss = self._loss(val_fake_samples_gen * val_target_availabilities, val_targets_position)\n",
    "\n",
    "                    # Calculate Validation loss of discriminator                                        \n",
    "                    val_fake_dis_out = self._discriminator(val_fake_samples_gen)\n",
    "                    val_fake_dis_label = fake_label[:numGenerated] \n",
    "                    val_fake_dis_loss = self._loss(val_fake_dis_out, val_fake_dis_label)\n",
    "\n",
    "                    val_dis_loss = val_real_dis_loss + val_fake_dis_loss\n",
    "\n",
    "                    # Plot Validation loss\n",
    "                    val_plot_dis_s = plot_dis_s * smooth_factor + val_dis_loss * (1 - smooth_factor)\n",
    "                    val_plot_gen_s = plot_gen_s * smooth_factor + val_gen_loss * (1 - smooth_factor)\n",
    "                    val_plot_ws = plot_ws * smooth_factor + (1 - smooth_factor)\n",
    "                    val_dis_losses.append(val_plot_dis_s / val_plot_ws)\n",
    "                    val_gen_losses.append(val_plot_gen_s / val_plot_ws)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('Iteration {0}/{1}: dis loss = {2:.4f}, gen loss = {3:.4f}'.format(step, max_steps, dis_loss, gen_loss))\n",
    "                    \n",
    "                # Save our loss graph\n",
    "                    \n",
    "                if step % self.val == 0:\n",
    "                    fig = plt.figure(figsize = (8, 8))   \n",
    "                    plt.plot(dis_losses)\n",
    "                    plt.plot(val_dis_losses)\n",
    "                    \n",
    "                    plt.title('discriminator loss')\n",
    "                    plt.xlabel('iterations')\n",
    "                    plt.ylabel('loss')\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.plot(gen_losses)\n",
    "                    plt.plot(val_gen_losses)                    \n",
    "                    plt.title('generator loss')\n",
    "                    plt.xlabel('iterations')\n",
    "                    plt.ylabel('loss')\n",
    "                    plt.show()\n",
    "                    \n",
    "            # Save model weights\n",
    "                    \n",
    "            torch.save(gan.state_dict(), \"gan_yaw_v1_\" + str(epoch)+ \".pt\")\n",
    "            \n",
    "            # Save loss graph\n",
    "            \n",
    "            fig = plt.figure(figsize = (8, 8))   \n",
    "            \n",
    "            plt.plot(dis_losses)\n",
    "            plt.plot(val_dis_losses)\n",
    "\n",
    "            plt.title('discriminator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.savefig(\"discriminator_yaw_v1_epoch_\" + str(epoch) + '.png')\n",
    "\n",
    "            plt.plot(gen_losses)\n",
    "            plt.plot(val_gen_losses)                    \n",
    "            plt.title('generator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.savefig(\"generator_yaw_v1_epoch_\" + str(epoch) + '.png')\n",
    "            print('... Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seongohryoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n"
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (_l2_loss): MSELoss()\n",
       "  (_discriminator): Discriminator(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=6400, out_features=3200, bias=True)\n",
       "      (1): BatchNorm1d(3200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=3200, out_features=1600, bias=True)\n",
       "      (5): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (7): Dropout(p=0.5, inplace=False)\n",
       "      (8): Linear(in_features=1600, out_features=800, bias=True)\n",
       "      (9): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "      (12): Linear(in_features=800, out_features=1, bias=True)\n",
       "    )\n",
       "    (lstm): LSTM(2, 128, batch_first=True)\n",
       "  )\n",
       "  (_generator): Generator(\n",
       "    (DecoderLSTM_LyftModel): DecoderLSTM_LyftModel(\n",
       "      (encoderLSTM): EncoderLSTM_LyftModel(\n",
       "        (Encoder_lstm): LSTM(3, 128, batch_first=True)\n",
       "      )\n",
       "      (Decoder_lstm): LSTM(128, 128, batch_first=True)\n",
       "    )\n",
       "    (fcn_en_state_dec_state): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_classification_loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganModel = GAN()\n",
    "ganModel.load_state_dict(torch.load(\"gan_yaw_v1_0.pt\"))\n",
    "ganModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/185990 [00:00<?, ?it/s]/Users/seongohryoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/Users/seongohryoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/Users/seongohryoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/Users/seongohryoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "  1%|          | 999/185990 [02:37<8:05:13,  6.35it/s] \n"
     ]
    }
   ],
   "source": [
    "future_coords_offsets_pd = []\n",
    "real_target = []\n",
    "target_availabilities = []\n",
    "timestamps = []\n",
    "agent_ids = []\n",
    "num_iter = 0\n",
    "\n",
    "# Start testing\n",
    "with torch.no_grad():\n",
    "    dataiter = tqdm(test_dataloader)\n",
    "    \n",
    "    # Load test set\n",
    "    for data in dataiter:\n",
    "        history_positions = data['history_positions'].to(device)\n",
    "        history_yaws = data['history_yaws']\n",
    "        timestamps.append(data[\"timestamp\"].numpy().copy())\n",
    "        agent_ids.append(data[\"track_id\"].numpy().copy())\n",
    "        real_target.append(data[\"target_positions\"])\n",
    "        target_availabilities.append(data[\"target_availabilities\"])\n",
    "        \n",
    "\n",
    "        # Set the generator to evaluation mode, to make batchnorm stats stay fixed\n",
    "        ganModel._generator.eval()\n",
    "        future_coords_offsets_pd.append(ganModel._generator(torch.cat([history_positions, history_yaws], dim = 2)))\n",
    "        num_iter += 1\n",
    "        \n",
    "        # Test on first 1000 batches\n",
    "        if num_iter == 1000:\n",
    "            break\n",
    "            \n",
    "# Save the result            \n",
    "torch.save(future_coords_offsets_pd, \"ganv1_future.pt\")\n",
    "torch.save(real_target, \"ganv1_target.pt\")\n",
    "torch.save(target_availabilities, \"ganv1_t_avail.pt\")\n",
    "torch.save(timestamps, \"ganv1_timestamps.pt\")\n",
    "torch.save(agent_ids, \"ganv1_ids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesss result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_coords_offsets_pd = torch.stack(future_coords_offsets_pd)\n",
    "target_availabilities = torch.stack(target_availabilities)\n",
    "target_availabilities = target_availabilities.view(1000, 32, 50, 1)\n",
    "real_target = torch.stack(real_target)\n",
    "real_target  = real_target * target_availabilities\n",
    "future_coords_offsets_pd = future_coords_offsets_pd * target_availabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MSE loss on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.5536)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss(reduction = 'mean')\n",
    "print(loss(future_coords_offsets_pd, real_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
